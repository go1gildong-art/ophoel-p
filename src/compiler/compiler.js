import { tokenize } from './lexer.js';
import { parse } from './parser.js';
import { transform } from "./transformer.js";
import { makeIr } from "./irgen.js";
import { generate } from "./generator.js";

import { lispify } from "./lispifyast.js";
// Load Configs
// const config = JSON.parse(fs.readFileSync('./configs.json', 'utf8'));


const code =
`
choose {
say!!("1");
} or {
say!!("2");
} or {
say!!("3");
}

`;

const config = { my_arr: [1, 2, 3], room_anchor_tag: "room_anchor", room_s: { radius: 7, tag: "room_s" } };

export function compile(sourceCode, config, fileName) {
    // 1. Raw text to Tokens
    let tokens = tokenize(sourceCode, config, fileName);

    // 2. parse tokens to get string mcfunction output
    let ast = parse(tokens);

    // 3. flatten and solve all compile time computations
    let processedAst = transform(ast, config);

    // 4. get lower ast to make ir
    let ir = makeIr(processedAst);

    // 4. generate mcfunction from processed ast
    let commands = generate(ir);

    return ["## This mcfunction is generated by Ophoel compiler.", ...commands].join("\n");
}

// console.log("");
// console.log(tokenize(code, config, "source.oph"));
// console.log(JSON.stringify(parse(tokenize(code, config, "source.oph"))) + "\n");
// console.log(JSON.stringify(transform(parse(tokenize(code, config, "source.oph")), config)) + "\n");
// console.log(JSON.stringify(makeIr(transform(parse(tokenize(code, config, "source.oph")), config))) + "\n");
console.log(compile(code, config, "source.oph") + "\n\n");

// console.log(lispify(parse(tokenize(code, config, "source.oph"))) + "\n");